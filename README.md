# Gradiente Descendente

Metodo de **gradiente descendente** es una tecnica computacional utilizada para hallar el minimo de una funcion, es decir, encontrar el valor que logra minimizar la salida de una *funcion*, en el caso de el aprendizaje automatico, esta *funcion* toma por nombre funcion de costo.

Es usual encontrarse con la necesidad de reducir una funcion, por ejemplo cuadrada y que depende de varios parametros, que iterativamente con el algoritmo de gradiente descendente logra encontrar el minimo, sea local o con suerte el global.

Esto con la intencion de lograr ajustar aquellos parametros inmersos en la funcion, y reducir el 'costo' de un modelo que busca ajustar sus parametros.


